{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aedb5f29-01ad-4643-bf10-2f25ec2f599b",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee242296-ad3c-41e4-9539-3597c444a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "# DataLoader, Transformation\n",
    "# Multilayer Neural Net, Activation function\n",
    "# Loss and Optimizer\n",
    "# Training Loop\n",
    "# Model Evaluation\n",
    "# GPU Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f23c98b2-4d38-43ee-93a5-e5aca970266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2db1f4c4-69d0-471e-a683-11a806b99fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "input_size = 784 # 28*28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba0a1e0d-c9c4-4c98-bfac-aef22e5e3c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/MNIST/raw/train-images-idx3-ubyte.gz to ./datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ./datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ./datasets/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112.7%\n",
      "/home/keshavchaurasia/workspace/ml/pytorch_venv/lib/python3.6/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./datasets/MNIST/raw\n",
      "\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# MNISt\n",
    "train_dataset = torchvision.datasets.MNIST(root='./datasets', \n",
    "                                           train=True, \n",
    "                                           transform = transforms.ToTensor(), \n",
    "                                           download = True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./datasets', \n",
    "                                           train=False, \n",
    "                                           transform = transforms.ToTensor(), \n",
    "                                           download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cd24d2e-5772-4137-aa52-3a58b45337dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataloader\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1d435e4-a9ff-46ef-8f5e-81ab4929425e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# getting one example\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a9b6842-28db-4c7e-a4f0-fe2150ec14e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af262526-f1ca-4d2e-b284-cff2b895c4d9",
   "metadata": {},
   "source": [
    "## creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08dee997-b702-4b5f-9a12-2f66f78cc7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eeb3ffb-a208-4253-876b-e20d9579bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e14629b-0cf4-40fd-aab6-6d27ac714411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4409377-4de5-462c-8247-da813d7150e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # this will apply softmax for us\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6eb4b6d9-5fc1-4f7e-9b62-af5d1680be47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/5, step 100 / 600, loss 0.1360\n",
      "epoch 1/5, step 200 / 600, loss 0.0416\n",
      "epoch 1/5, step 300 / 600, loss 0.2322\n",
      "epoch 1/5, step 400 / 600, loss 0.1977\n",
      "epoch 1/5, step 500 / 600, loss 0.0606\n",
      "epoch 1/5, step 600 / 600, loss 0.1366\n",
      "epoch 2/5, step 100 / 600, loss 0.0670\n",
      "epoch 2/5, step 200 / 600, loss 0.1461\n",
      "epoch 2/5, step 300 / 600, loss 0.1799\n",
      "epoch 2/5, step 400 / 600, loss 0.0661\n",
      "epoch 2/5, step 500 / 600, loss 0.0992\n",
      "epoch 2/5, step 600 / 600, loss 0.1074\n",
      "epoch 3/5, step 100 / 600, loss 0.0411\n",
      "epoch 3/5, step 200 / 600, loss 0.0421\n",
      "epoch 3/5, step 300 / 600, loss 0.1198\n",
      "epoch 3/5, step 400 / 600, loss 0.0411\n",
      "epoch 3/5, step 500 / 600, loss 0.0552\n",
      "epoch 3/5, step 600 / 600, loss 0.1473\n",
      "epoch 4/5, step 100 / 600, loss 0.0278\n",
      "epoch 4/5, step 200 / 600, loss 0.1064\n",
      "epoch 4/5, step 300 / 600, loss 0.0430\n",
      "epoch 4/5, step 400 / 600, loss 0.1010\n",
      "epoch 4/5, step 500 / 600, loss 0.0570\n",
      "epoch 4/5, step 600 / 600, loss 0.0387\n",
      "epoch 5/5, step 100 / 600, loss 0.0529\n",
      "epoch 5/5, step 200 / 600, loss 0.1081\n",
      "epoch 5/5, step 300 / 600, loss 0.0728\n",
      "epoch 5/5, step 400 / 600, loss 0.0737\n",
      "epoch 5/5, step 500 / 600, loss 0.0351\n",
      "epoch 5/5, step 600 / 600, loss 0.0770\n"
     ]
    }
   ],
   "source": [
    "# training_loooooop\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 100, 1, 28, 28\n",
    "        # 100, 784\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backwards\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1)%100 == 0:\n",
    "            print(f'epoch {epoch +1 }/{num_epochs}, step {i + 1} / {n_total_steps}, loss {loss.item():.4f}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9a89900-0da7-458b-84da-61aa300c1569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 10.1%\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        output = model(images)\n",
    "\n",
    "        # value, index\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    \n",
    "    print(f'accuracy = {acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d2fc1-c872-4514-895e-ee8c21795916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
